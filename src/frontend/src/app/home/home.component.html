<style>



    .flex-container {
        display: flex;
        flex-flow: row wrap;
        justify-content: center;
        padding-top: 20px;
        padding-left: 40px;
        padding-right: 40px;
    }

    .container123 {
        display: flex;
        flex-flow: row;
        justify-content: center;
    }

    .leftcontainer {
        display: flex;
        flex-basis: 50%;
        justify-content: flex-end;

    }

    .rightcontainter {
        padding-left: 20px;
        flex-basis: 50%;
        display: flex;
        flex-direction: column;
        align-items: flex-start;

    }

    .imagecontainer {
        display: flex;
        width: 50vw;

    }

    .images {
        display: flex;
        width: 90vw;
    }

    .verticalradiogroup {
        display: flex;
        flex-direction: column;
    }

    .example-spacer {
        flex: 1 1 auto;
    }

    .mat-toolbar h4 {
        font-style: normal;
        font-variant-ligatures: normal;
        font-variant-caps: normal;
        font-variant-numeric: normal;
        font-variant-east-asian: normal;
        font-weight: 100;
        font-stretch: normal;
        font-weight: bold;
        font-size: 16px;
        line-height: 32px;
        font-family: Roboto, "Helvetica Neue", sans-serif;
    }


    .panel {
        position: relative;
        background-size: 800px;
        background-position: center;
        background-repeat: no-repeat;
        height: 85vh;
        border-radius: 5px;
        color: #ffffff;
        cursor: pointer;
        flex: .5;
        margin: 10px;
        transition: all 700ms ease;
    }


    .panel.active {
        flex: 5;
    }

    .subright {
        width: 300px;
        padding-top: 44px;
    }

    .buttonsection {
        display: flex;
        flex-flow: row wrap;
        padding: 20px;
        justify-content: center;
        grid-gap: 25px;
    }

    .countsection {
        padding-top: 20px;
    }

    .mat-slider-horizontal {
        width: 100%;
    }

    .mat-toolbar {
        background: #0076a5;
        color: white;
    }

    .leftleftcontainer {
        display: flex;
        flex-direction: column;
        padding-right: 20px;
        align-items: flex-end;
    }

    mat-slide-toggle {
        padding-right: 10px;
    }

    .mat-slide-toggle.mat-checked .mat-slide-toggle-bar {
        background-color: rgb(170 235 168);
    }

    .mat-slide-toggle.mat-checked .mat-slide-toggle-thumb {
        background-color: #42b36a;
    }

    .btn {
        border: none;
        outline: none;
        padding: 5px 5px;
        background-color: #f1f1f1;
        cursor: pointer;
        font-size: 18px;
        width: 150px;
        margin-bottom: 5px;
    }

    /* Style the active class, and buttons on mouse-over */
    .active,
    .btn:hover {
        background-color: #666;
        color: white;
    }

    #myDIV {
        display: flex;
        flex-direction: row;
    }

    .firstcolumn {
        display: flex;
        flex-direction: column;
        margin-right: 5px;
    }
    a{
        color:white
    }
    .customtext{
        font-family: "Open Sans", sans-serif;
        color: #444444;
        font-size: 1rem;
        font-weight: 400;
        line-height: 1.5;
        text-align:justify;
    }
.fixed-top {
    position: fixed;
    top: 0;
    right: 0;
    left: 0;
    z-index: 1030;
}
</style>

<p>
    <mat-toolbar class="fixed-top">
        <span>Wisconsin Trails</span>
        <span class="example-spacer"></span>
        <span><h4>Home&nbsp;&nbsp;&nbsp;</h4></span>
        <span><h4><a href="/annotate" style="text-decoration: none;">Annotate</a> &nbsp;&nbsp;&nbsp;</h4></span>
        <span><h4><a href="/teams" style="text-decoration: none;">Team</a>&nbsp;&nbsp;&nbsp;</h4></span>
    </mat-toolbar>
</p>


<section id="hero" class="d-flex flex-column justify-content-end align-items-center" style="margin-top: -12px;">
    <div id="heroCarousel" class="container carousel carousel-fade" data-ride="carousel">
      <div class="carousel-item active">
        <div class="carousel-container">
          <h2 class="animate__animated animate__fadeInDown">Welcome to <span>CAMinos</span></h2>
          <p class="animate__animated fanimate__adeInUp">A companion tool for Snapshot Wisconsin</p>
          <a href="/home/#about" class="btn-get-started animate__animated animate__fadeInUp scrollto">Learn More</a>
        </div>
      </div>
    </div>
  </section>

  <section id="about" class="about">
    <div class="container" style="max-width: 920px;">

      <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 0px;margin-bottom: -15px;">
        <h2>About</h2>
        <p>Snapshot Wisconsin</p>
      </div>

      <div class="row content aos-init aos-animate" data-aos="fade-up">
        <div class="col-lg-6">
          <p class="customtext">
            Snapshot Wisconsin is an effort led by Wisconsinâ€™s Department of Natural Resources to maintain a statewide network of trail cameras, monitor wildlife year-round, and support decisions regarding wildlife conservation and management. The network consists of thousands of cameras and millions of pictures. However, images captured from trail cameras are outsourced to the public and are manually annotated by volunteers. Our project aims to improve this current paradigm of manual, crowdsourced annotations by implementing machine-learned recommendations to help fuel public conservation efforts.
          </p>

          <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 40px;margin-bottom: -15px;">
            <p>Our Project</p>
          </div>
    
          <p class="customtext">
            CAMinos applies computer vision to trail camera images to help automate the annotation process. Our deep learning system predicts both the animal species and the count of animals caught on trail camera images using an ensemble approach that consists of both object detection and classification algorithms. These predictions are then supplied as recommendations to users as they label images in our custom-built annotation tool. Caminos streamlines the annotation process for users, resulting in much faster annotation times and providing a valuable resource to the wildlife conservation community.
          </p>
        </div>
        <!-- <div class="col-lg-6 pt-4 pt-lg-0">          
          <a href="#features" class="btn-learn-more">Learn More</a>
          <img src="/assets/images/snapshot-logo-9.jpeg" alt="">
        </div> -->
      </div>
    </div>
  </section>

  <section id="about" class="about" style="padding-top: 20px;">
    <div class="container" style="max-width: 920px;">

      <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 0px;margin-bottom: -15px;">
        <h2>Data</h2>
        <p>Serengeti Dataset</p>
        <p style="margin-top: 15px;margin-bottom: 0px;font-size: 22px;">16GB with 260,000 images</p>
      </div>

      <div class="row content aos-init aos-animate" data-aos="fade-up">
        <div class="col-lg-6">
          <p class="customtext">
            Snapshot Serengeti is a camera-trap dataset with images of animals from the Serengeti ecosystem in Africa. 
            Images were consecutively taken in groups of three, when triggered by cameras with infrared and motion sensors. 
            When a camera captures three images at a time, we define this action to be an event. When an event is captured, 
            camera triggers are blocked for one minute. 
          </p>
          <p class="customtext">
            The dataset was made available in Kaggle and provided species labels, counts, and bounding box data. 
            We trained models on the dataset and used their learned weights to apply transfer learning to our primary dataset: Snapshot Wisconsin. 
          </p>

          <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 40px;margin-bottom: -15px;">
            <p>Wisconsin dataset</p>
            <p style="margin-top: 15px;margin-bottom: 0px;font-size: 22px;">2GB with 30,000 images</p>
          </div>
    
          <p class="customtext">
            Snapshot Wisconsin, made available by the Wisconsin DNR team, is a camera-trap dataset with images of animals found along trails 
            throughout forests in Wisconsin. Cameras were triggered by heat and movement, and took three images in a short interval when triggered. 
            When an event is captured, camera triggers are blocked for 15 seconds.
          </p>
          <p class="customtext">
            The provided dataset contained labels and counts, which were supplied by a combination of expert annotators and crowdsourced 
            users that utilized the citizen-science platform, <a href="https://www.zooniverse.org/projects/zooniverse/snapshot-wisconsin/classify" style="color: #444444;">Zooniverse</a>. 
            The labeled data did not contain bounding box information so the team 
            manually labeled a subset of 30,000 images using <a href="https://www.makesense.ai/" style="color: #444444;">makesense.ai</a> to train our models.          
          </p>
        </div>
      </div>
    </div>
  </section>

  <section id="about" class="about" style="padding-top: 20px;">
    <div class="container" style="max-width: 920px;">

      <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 0px;margin-bottom: -15px;">
        <h2>Models & Performance</h2>
        <p>Models</p>
      </div>

      <div class="row content aos-init aos-animate" data-aos="fade-up">
        <div class="col-lg-6">
          <p class="customtext">
            Caminos utilizes a two-stage modeling process to generate predictions on an event of three images. During the first stage, 
            we trained YOLO object detection and EfficientNet classification models to differentiate between blank and non-blank images. 
            For the second stage, we train another set of YOLO and EfficientNet models to classify images into ten animal classes that were 
            most prevalent in the Snapshot Wisconsin dataset:
          </p>
          <div class="container123">
            <div class="customtext leftcontainer">
              <ul>
              <li>Bear</li>
              <li>Rabbit</li>
              <li>Coyote</li>
              <li>Deer</li>
              <li>Elk</li>
            </ul>
            </div>
            <div class="customtext rightcontainter">
              <ul>
                <li>Fox</li>
                <li>Opossum</li>
                <li>Raccoon</li>
                <li>Turkey</li>
                <li>Wolf</li>
              </ul>
              </div>
          </div>    
          <p class="customtext">
            As an object detection model, YOLO produces countsâ€”on top of its classificationsâ€”of animal events in each image. Since EfficientNet 
            is purely a classification model and does not supply counts in its predictions, we use a third model, Megadetector, which has been pre-trained 
            on several hundred thousand camera trap images from a variety of ecosystems. Megadetector only produces counts and bounding box predictions on 
            each image. Thus, for both classification and counting tasks, we are able to ensemble multiple models to produce predictions with better accuracy.
          </p>

          <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 40px;margin-bottom: -15px;">
            <p>Performance</p>
          </div>
    
          <p class="customtext">
            CAMinos applies computer vision to trail camera images to help automate the annotation process. Our deep learning system predicts both the animal species and the count of animals caught on trail camera images using an ensemble approach that consists of both object detection and classification algorithms. These predictions are then supplied as recommendations to users as they label images in our custom-built annotation tool. Caminos streamlines the annotation process for users, resulting in much faster annotation times and providing a valuable resource to the wildlife conservation community.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section id="about" class="about" style="padding-top: 20px;">
    <div class="container" style="max-width: 920px;">

      <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 0px;margin-bottom: -15px;">
        <h2>Architecture & Web Application</h2>
        <p>Architecture</p>
      </div>

      <div class="row content aos-init aos-animate" data-aos="fade-up">
        <div class="col-lg-6">
          <p class="customtext">
            Some text will go here that explains about the Architecture
          </p>
  
          <div class="section-title aos-init aos-animate" data-aos="zoom-out" style="margin-top: 40px;margin-bottom: -15px;">
            <p>Web Application</p>
          </div>
    
          <p class="customtext">
            CAMinos applies computer vision to trail camera images to help automate the annotation process. Our deep learning system 
            predicts both the animal species and the count of animals caught on trail camera images using an ensemble approach that 
            consists of both object detection and classification algorithms. These predictions are then supplied as recommendations to 
            users as they label images in our custom-built annotation tool. Caminos streamlines the annotation process for users, resulting in 
            much faster annotation times and providing a valuable resource to the wildlife conservation community.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- <section id="about" class="about" style="padding-top: 20px;">
    <div class="container" style="max-width: 920px;">
      <div class="section-title aos-init aos-animate" data-aos="zoom-out">
        <h2>About</h2>
        <p>Sample 2 column layout</p>
      </div>
      <div class="row content aos-init aos-animate" data-aos="fade-up">
        <div class="col-lg-6">
          <div class="container123">
            <p class="customtext leftcontainer">
              Snapshot Wisconsin is an effort led by Wisconsinâ€™s Department of Natural Resources to maintain a statewide network of trail cameras, 
              monitor wildlife year-round, and support decisions regarding wildlife conservation and management. 
            </p>
            <p class="customtext rightcontainter">
              Wisconsinâ€™s Department of Natural Resources maintains a statewide network of trail cameras to monitor wildlife year-round through 
              their project Snapshot Wisconsin, supporting decisions regarding wildlife conservation and management. This network consists of 
              thousands of cameras taking millions of pictures per year. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </section> -->

<footer id="footer">
  <div class="container">
    <h3>CAMinos</h3>
    <p>Snapshot Wisconsin.</p>
  </div>
  <!-- <div class="col-lg-6 pt-4 pt-lg-0">
    <img src="/assets/images/snapshot-logo-9.jpeg" alt="">
  </div> -->
</footer>