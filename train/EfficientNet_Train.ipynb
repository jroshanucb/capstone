{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d6b9123ba26432fada6134f20ec9623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7494c56c1064bb2b54fa95a4897208a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19c18d740a75461cb81d65678987b748",
              "IPY_MODEL_8a291cd27d5c4755bc1bba4bf65156ad",
              "IPY_MODEL_366807e619e448db9e746a09a24eb4fd"
            ]
          }
        },
        "f7494c56c1064bb2b54fa95a4897208a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19c18d740a75461cb81d65678987b748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d5622777c7d4c5ebb60bb3851e31cb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f97f279f8f7e4fcf97608412e955b0c1"
          }
        },
        "8a291cd27d5c4755bc1bba4bf65156ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21eaac0bcdf742888fc2bcea543c4387",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93f94d4136eb4dd181de936cc6cb0c67"
          }
        },
        "366807e619e448db9e746a09a24eb4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79e0fccbdf194be3b00007c5ed3a7a5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:19&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b05399e717b4b2e91fcbc6665048d94"
          }
        },
        "4d5622777c7d4c5ebb60bb3851e31cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f97f279f8f7e4fcf97608412e955b0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21eaac0bcdf742888fc2bcea543c4387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93f94d4136eb4dd181de936cc6cb0c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79e0fccbdf194be3b00007c5ed3a7a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b05399e717b4b2e91fcbc6665048d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f60b15dd3a542daa59c9dc4b28924e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae65eb3493d1412cb0464eeca483ffd7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45442bdb62e54dcca878d62004f1c89c",
              "IPY_MODEL_d2c3660f135642ceba59f7e942922029",
              "IPY_MODEL_349714b81d50464992aee74f35739ff6"
            ]
          }
        },
        "ae65eb3493d1412cb0464eeca483ffd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45442bdb62e54dcca878d62004f1c89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dadb7bc4196844fcb6203b5a8d0dbbc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfb22df5a1ce4607bca49a77f45599e9"
          }
        },
        "d2c3660f135642ceba59f7e942922029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3b16398ecc2404088bc375da892a0fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 597,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 597,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9840b13e46c447ba8fcf290cded8de1"
          }
        },
        "349714b81d50464992aee74f35739ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76877b954e9b4eeab32822242c2c13b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 597/597 [04:38&lt;00:00,  2.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4034a6b18f0e423cb0ea385cf3460f82"
          }
        },
        "dadb7bc4196844fcb6203b5a8d0dbbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfb22df5a1ce4607bca49a77f45599e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3b16398ecc2404088bc375da892a0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9840b13e46c447ba8fcf290cded8de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76877b954e9b4eeab32822242c2c13b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4034a6b18f0e423cb0ea385cf3460f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d4b52a68a244dbdbf2527577aff8be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9654c0080b0d463388e693e23c350ea8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c79a54bcfda48aa9fbafa38054c777d",
              "IPY_MODEL_858ec94e9a03450bb52fcc1bd4618ea2",
              "IPY_MODEL_cdde1720c5ec44a3868ae40d853acb9b"
            ]
          }
        },
        "9654c0080b0d463388e693e23c350ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c79a54bcfda48aa9fbafa38054c777d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a1d59d2682645e4a646a2a6ede7fb89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2eb86d3a5fb24be5b12bbe498dcd65f1"
          }
        },
        "858ec94e9a03450bb52fcc1bd4618ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee8fdf5f32e54c29a801523fa20b25bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 597,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 597,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6be3292115e54434851e04aa520e22c9"
          }
        },
        "cdde1720c5ec44a3868ae40d853acb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5560dbae5f44fad814c9e7d36d1fc3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 597/597 [01:34&lt;00:00,  6.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46c9b60bac88480083ca0bd664d5f91e"
          }
        },
        "1a1d59d2682645e4a646a2a6ede7fb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2eb86d3a5fb24be5b12bbe498dcd65f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee8fdf5f32e54c29a801523fa20b25bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6be3292115e54434851e04aa520e22c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5560dbae5f44fad814c9e7d36d1fc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46c9b60bac88480083ca0bd664d5f91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "_pV2pygSCg_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0d6b9123ba26432fada6134f20ec9623",
            "f7494c56c1064bb2b54fa95a4897208a",
            "19c18d740a75461cb81d65678987b748",
            "8a291cd27d5c4755bc1bba4bf65156ad",
            "366807e619e448db9e746a09a24eb4fd",
            "4d5622777c7d4c5ebb60bb3851e31cb7",
            "f97f279f8f7e4fcf97608412e955b0c1",
            "21eaac0bcdf742888fc2bcea543c4387",
            "93f94d4136eb4dd181de936cc6cb0c67",
            "79e0fccbdf194be3b00007c5ed3a7a5d",
            "2b05399e717b4b2e91fcbc6665048d94"
          ]
        },
        "id": "fvTW7GFdCfOf",
        "outputId": "fd4f3bee-c3bf-4e2b-aa48-155e09e64b36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d6b9123ba26432fada6134f20ec9623",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm().pandas()\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB-lwGoPH3AX",
        "outputId": "037e5651-226c-4cf9-e92d-0562449f4fd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "pRsN7OOVCof7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "ijniLlwxCphn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "papAUasHCrWU",
        "outputId": "08108037-858b-4e5c-fe40-c23ea767b4c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=1b2957bc1802ed8032b4fe72772f67d03fdb9664a7192eab69334bab72cdd5f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function \n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vPJL8bh2CuxD",
        "outputId": "2d90327b-5e21-4a7f-8541-39ed89dfd6d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## folder structure is train/val/test\n",
        "## within each folder split: there are 11 folders each corresponding to a class\n",
        "## the individual folders contain all the images of their respective class\n",
        "\n",
        "data_dir = '/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_v4_1'\n",
        "num_classes = 11\n",
        "feature_extract = False\n",
        "batch_size = 8"
      ],
      "metadata": {
        "id": "KbvK3dvQCxjX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train script\n",
        "\"\"\"\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "  \n",
        "\n",
        "    with wandb.init(project=\"trails\", entity=\"trails_team\", config={\"epochs\": num_epochs, \"arch\": model_name, \"batch_size\": batch_size, \"lr\": optimizer.state_dict()['param_groups'][0]['lr'],\\\n",
        "                                                                    \"momentum\": optimizer.state_dict()['param_groups'][0]['momentum'],\\\n",
        "                                                                    \"WEIGHT_DECAY\": optimizer.state_dict()['param_groups'][0]['weight_decay']}):\n",
        "      since = time.time()\n",
        "\n",
        "      val_acc_history = []\n",
        "      val_loss_history = []\n",
        "      train_acc_history = []\n",
        "      train_loss_history = []    \n",
        "      \n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      best_acc = 0.0\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "          print('-' * 10)\n",
        "\n",
        "          # Each epoch has a training and validation phase\n",
        "          for phase in ['train', 'val']:\n",
        "              if phase == 'train':\n",
        "                  model.train()  # Set model to training mode\n",
        "                  ### test loop\n",
        "                  # for m in model.modules():\n",
        "                  #   if isinstance(m, nn.BatchNorm2d):\n",
        "                  #     m.track_running_stats=True\n",
        "                  #     m.train()\n",
        "              else:\n",
        "                  model.eval()   # Set model to evaluate mode\n",
        "                  ### test loop\n",
        "                  # for m in model.modules():\n",
        "                  #   if isinstance(m, nn.BatchNorm2d):\n",
        "                  #     m.track_running_stats=False\n",
        "                  #     m.eval()\n",
        "\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "              running_corrects_top5 = 0\n",
        "\n",
        "              # Iterate over data.\n",
        "              for inputs, labels in dataloaders[phase]:\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      # Get model outputs and calculate loss\n",
        "                      # Special case for inception because in training it has an auxiliary output. In train\n",
        "                      #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                      #   but in testing we only consider the final output.\n",
        "                      if is_inception and phase == 'train':\n",
        "                          # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                          outputs, aux_outputs = model(inputs)\n",
        "                          loss1 = criterion(outputs, labels)\n",
        "                          loss2 = criterion(aux_outputs, labels)\n",
        "                          loss = loss1 + 0.4*loss2\n",
        "                      else:\n",
        "                          outputs = model(inputs)\n",
        "                          loss = criterion(outputs, labels)\n",
        "\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                      ## top 5 predictions\n",
        "                      labels_top5 = labels.view(-1,1)\n",
        "                      maxk = max((1,5))\n",
        "                      _, preds_top5 = outputs.topk(maxk, 1, True, True)\n",
        "\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                  # statistics\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "                  #running_corrects_top5 += torch.sum(preds_top5 == labels.data)\n",
        "                  running_corrects_top5 += torch.eq(preds_top5, labels_top5).sum().float().item()\n",
        "\n",
        "              epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "              epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "              epoch_acc_top5 = running_corrects_top5 / len(dataloaders[phase].dataset)\n",
        "\n",
        "              if phase == 'train':\n",
        "                  train_acc_history.append(epoch_acc)\n",
        "                  train_loss_history.append(epoch_loss)\n",
        "                  wandb.log({\"epoch\": epoch, \"acc1/train\": epoch_acc, \"Loss/train\": epoch_loss, \"acc5/train\": epoch_acc_top5})\n",
        "\n",
        "              print('{} Loss: {:.4f} Acc: {:.4f} Acc_Top5 {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_acc_top5))\n",
        "\n",
        "              # deep copy the model\n",
        "              if phase == 'val' and epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "              if phase == 'val':\n",
        "                  val_acc_history.append(epoch_acc)\n",
        "                  val_loss_history.append(epoch_loss)     \n",
        "                  wandb.log({\"epoch\": epoch, \"acc1/val\": epoch_acc, \"Loss/val\": epoch_loss, \"acc5/val\": epoch_acc_top5})    \n",
        "\n",
        "          print()\n",
        "\n",
        "      time_elapsed = time.time() - since\n",
        "      print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "      print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "      # load best model weights\n",
        "      model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss_history, train_acc_history, val_loss_history, val_acc_history\n",
        "\n",
        "### requires_grad = False ----> freeze layers\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "fJ0MwpbbDEF6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "\"\"\"\n",
        "fine-tuning training script\n",
        "\"\"\"\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"efficientnetb5\":\n",
        "      if use_pretrained == True:\n",
        "        model_ft = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "      else:\n",
        "        model_ft = EfficientNet.from_name('efficientnet-b5')\n",
        "\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft._fc.in_features\n",
        "      # model_ft._fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
        "      # model_ft._fc = nn.Linear(num_ftrs, num_classes)\n",
        "      model_ft._fc = nn.Sequential(nn.Linear(num_ftrs, 512),\n",
        "                                   nn.Linear(512, num_classes))\n",
        "\n",
        "      \n",
        "      input_size = 456\n",
        "\n",
        "    elif model_name == \"efficientnetb7\":\n",
        "      if use_pretrained == True:\n",
        "        model_ft = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "      else:\n",
        "        model_ft = EfficientNet.from_name('efficientnet-b7')\n",
        "\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft._fc.in_features\n",
        "      # model_ft._fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
        "      # model_ft._fc = nn.Linear(num_ftrs, num_classes)\n",
        "      model_ft._fc = nn.Sequential(nn.Linear(num_ftrs, 512),\n",
        "                                   nn.Linear(512, num_classes))\n",
        "\n",
        "      input_size = 600\n",
        "\n",
        "    elif model_name == \"efficientnetb0\":\n",
        "      if use_pretrained == True:\n",
        "        model_ft = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "      else:\n",
        "        model_ft = EfficientNet.from_name('efficientnet-b0')\n",
        "\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft._fc.in_features\n",
        "\n",
        "      model_ft._fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "      input_size = 224\n",
        "      \n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
        " If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
        "\n",
        " In finetuning, we start with a pretrained model and update all of the model’s parameters for our new task, in essence retraining the whole model. \n",
        "    feature_extract = False\n",
        "    use_pretrained = True\n",
        " In feature extraction, we start with a pretrained model and only update the final layer weights from which we derive predictions.\n",
        "    feature_extract = True\n",
        "    use_pretrained = True\n",
        " Train from scratch:\n",
        "    feature_extract = False\n",
        "    use_pretrained = False\n",
        "\"\"\"\n",
        "model_name='efficientnetb5'\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyy85yRuDOo8",
        "outputId": "938c1e8e-7419-402d-b6ac-95df6e0835d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n",
            "EfficientNet(\n",
            "  (_conv_stem): Conv2dStaticSamePadding(\n",
            "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
            "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "  )\n",
            "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_blocks): ModuleList(\n",
            "    (0): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (1): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (2): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (3): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (4): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (5): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (6): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (7): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (8): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (9): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (10): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (11): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (12): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (13): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (14): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (15): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (16): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (17): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (18): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (19): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (20): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (21): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (22): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (23): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (24): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (25): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (26): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (27): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (28): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (29): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (30): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (31): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (32): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (33): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (34): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (35): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (36): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (37): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (38): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "  )\n",
            "  (_conv_head): Conv2dStaticSamePadding(\n",
            "    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "    (static_padding): Identity()\n",
            "  )\n",
            "  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (_dropout): Dropout(p=0.4, inplace=False)\n",
            "  (_fc): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=11, bias=True)\n",
            "  )\n",
            "  (_swish): MemoryEfficientSwish()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRst0aBDDjTE",
        "outputId": "5ecd2fdf-fcac-46cd-c239-044e61351de6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcBP9jSHDrHa",
        "outputId": "b2a505f0-e3d4-49e6-b428-5c3702c2585a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bear', 'blank', 'cottontail_snowshoehare', 'coyote', 'deer', 'elk', 'foxgray_foxred', 'opossum', 'raccoon', 'turkey', 'wolf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "DePXkFyQDvCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the pretrained version of the model used for this run\n",
        "model_name = 'efficientnetb5'\n",
        "num_epochs = 30\n",
        "finetuned_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True)\n",
        "finetuned_model = finetuned_model.to(device)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "finetuned_optimizer = optim.SGD(finetuned_model.parameters(), lr=0.0001, momentum=0.9)\n",
        "finetuned_criterion = nn.CrossEntropyLoss()\n",
        "finetuned_trained_model,finetuned_train_loss_history, finetuned_train_acc_history, finetuned_val_loss_history, finetuned_val_acc_history = train_model(finetuned_model, dataloaders_dict, finetuned_criterion, finetuned_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n"
      ],
      "metadata": {
        "id": "GTeg0HkEDvut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(finetuned_trained_model.state_dict(), '/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_model_runs/efficientnetb5_25epochs_finetuned_model_yolosplits4_456_BasePlusBlank.pt')"
      ],
      "metadata": {
        "id": "Q-w-KlcLDz3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Predictions"
      ],
      "metadata": {
        "id": "8pCwpRVSD6oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint = torch.load(Path('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_model_runs/efficientnetb5_25epochs_finetuned_model_yolosplits4_456_BasePlusBlank.pt'))\n",
        "model_name = 'efficientnetb5'\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False) #change True/False\n",
        "model_ft.load_state_dict(checkpoint)\n",
        "model_ft.eval()"
      ],
      "metadata": {
        "id": "zQ1xPOb8D8N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_actuals = []\n",
        "test_preds = []\n",
        "model_ft = model_ft.to(device)\n",
        "model_ft.eval()\n",
        "\n",
        "for i, (inputs, labels) in enumerate(dataloaders_dict['test']):\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  outputs = model_ft(inputs)\n",
        "  _, preds = torch.max(outputs, 1)\n",
        "\n",
        "  for j in range(inputs.size()[0]):\n",
        "    #print(j)\n",
        "    test_actuals.append(class_names[labels[j]])\n",
        "    test_preds.append(class_names[preds[j]])"
      ],
      "metadata": {
        "id": "9gUGLmNJECv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(test_actuals, test_preds, labels=class_names)"
      ],
      "metadata": {
        "id": "VLmV4aGdEIW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_actuals, test_preds, digits = 4))"
      ],
      "metadata": {
        "id": "mVEEuqKwEJdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "index = class_names\n",
        "columns = class_names\n",
        "\n",
        "cm = confusion_matrix(test_actuals, test_preds)\n",
        "cm_df = pd.DataFrame(cm, columns, index)\n",
        "plt.figure(figsize = (10,6))\n",
        "ax = sns.heatmap(cm_df, annot = True, fmt='d', cmap = \"Blues\")\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "#ax.get_ylim()\n",
        "ax.set_ylim(11, 0)"
      ],
      "metadata": {
        "id": "6CvdWcEzELXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Event Level Predictions\n",
        "Group predictions into events"
      ],
      "metadata": {
        "id": "nE53_C-hFNLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "run model through every image in test and output a json file\n",
        "\n",
        "run again but for val (for Logistic Regression)\n",
        "\"\"\"\n",
        "species_image_dict = {}\n",
        "for animal in class_names:\n",
        "  folder_dir = os.listdir('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_v4_1/test/' + animal)\n",
        "  species_image_dict[animal] = folder_dir"
      ],
      "metadata": {
        "id": "Y5gy4t04FOv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "run predictions on all test images\n",
        "\"\"\"\n",
        "from PIL import Image\n",
        "\n",
        "classifications = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for animal in class_names:\n",
        "    subset_animal_image_list = species_image_dict[animal]\n",
        "    with tqdm(total = len(subset_animal_image_list)) as pbar:\n",
        "      for image in subset_animal_image_list:\n",
        "        image_path = '/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_v4_1/test/' + animal + '/' + image\n",
        "        pbar.set_description(\"processing {}: {} \".format(animal, image))\n",
        "\n",
        "        image_inst = Image.open(Path(image_path)).convert('RGB')\n",
        "        input = data_transforms['val'](image_inst).to(device)\n",
        "        input.unsqueeze_(0)\n",
        "\n",
        "        model_ft.to(device)\n",
        "        output = model_ft(input)\n",
        "\n",
        "        # _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        ## top5 pred\n",
        "        sm = nn.Softmax(dim=1)\n",
        "        probabilities = sm(output)\n",
        "\n",
        "        top_5_conf, i = output.topk(5)\n",
        "        prob, idx = probabilities.topk(5)\n",
        "\n",
        "        dict_preds = {}\n",
        "        itr = 0\n",
        "        for x in i.cpu().numpy()[0]:\n",
        "          if x in dict_preds:\n",
        "            dict_preds[int(x)].append(float(prob.cpu().detach().numpy()[0][itr]))\n",
        "          else:\n",
        "            dict_preds[int(x)] = [float(prob.cpu().detach().numpy()[0][itr])]\n",
        "          itr += 1\n",
        "\n",
        "        best_class = max(dict_preds, key=dict_preds.get)\n",
        "        species_name = class_names[best_class]\n",
        "        confidence_score = dict_preds[best_class]\n",
        "\n",
        "        #print(image, best_class, species_name, confidence_score[0])\n",
        "\n",
        "        classification = {\n",
        "              \"id\": image,\n",
        "              \"class\": int(best_class),\n",
        "              \"class_name\": species_name,\n",
        "              \"conf\": float(confidence_score[0]),\n",
        "              \"conf_dict\": dict_preds\n",
        "          }\n",
        "        \n",
        "        classifications.append(classification)\n",
        "        pbar.update(1)\n",
        "\n",
        "\n",
        "# animal/blank, count, species, img_name, conf"
      ],
      "metadata": {
        "id": "3CmAtFASFafT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_json = {'phase2_classification_results': classifications}\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/w210_capstone/JSON_outputs/phase2_efficientnetb5_456_25epochs_yolo_splits4-1_test_classifications_basePlusblanks.json\", \"w\") as fp:\n",
        "    json.dump(output_json, fp)"
      ],
      "metadata": {
        "id": "gM0MooR8FcXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model_results = pd.read_json('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/JSON_outputs/phase2_efficientnetb5_456_25epochs_yolo_splits4-1_test_classifications_basePlusblanks.json')\n",
        "df = model_results['phase2_classification_results'].apply(pd.Series)\n",
        "\n",
        "def extract_event_id(x):\n",
        "  if 'jpg' in x:\n",
        "    file = x.split('.jpg')[0]\n",
        "    event = file[:-1]\n",
        "    return event\n",
        "  else:\n",
        "    file = x.split('.jpeg')[0]\n",
        "    file = file.split('_')[0]\n",
        "    return file\n",
        "   \n",
        "df['event_id'] = df.apply(lambda x: extract_event_id(x.id), axis=1)"
      ],
      "metadata": {
        "id": "2mDQ33hQFd55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dict = {}\n",
        "for index, row in df.iterrows():\n",
        "  event_id = str(row['event_id'])\n",
        "  pred_class = row['class']\n",
        "  pred_conf = row['conf']\n",
        "  #print(event_id, pred_class, pred_conf)\n",
        "  \n",
        "  result_dict = {\n",
        "        \"class\": pred_class,\n",
        "        \"conf\": pred_conf\n",
        "    }\n",
        "  \n",
        "  if event_id in preds_dict:\n",
        "    preds_dict[event_id].append(result_dict)\n",
        "  else:\n",
        "    preds_dict[event_id] = [result_dict]"
      ],
      "metadata": {
        "id": "7SlZ0bEXFkzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "final_preds_dict = {}\n",
        "for key, value in preds_dict.items():\n",
        "  event_id = key\n",
        "  counts = Counter(d['class'] for d in value)\n",
        "\n",
        "  ## if all 3 predictions are different, defer to class with highest confidence\n",
        "  if len(counts) == 3:\n",
        "    highest_conf = max([x['conf'] for x in value])\n",
        "    pred_class = [x['class'] for x in value if x['conf']==highest_conf][0]\n",
        "  \n",
        "  ## if there is an even number of predictions (2), defer to class with higher confidence\n",
        "  elif sum(counts.values()) == 2:\n",
        "    # highest_conf = max([x['conf'] for x in value])\n",
        "    # pred_class = [x['class'] for x in value if x['conf']==highest_conf][0]\n",
        "\n",
        "    ## if there are even number of predictions (2), defer to class that appears more often\n",
        "    most_common = {'most_common': counts.most_common(1)[0][0]}\n",
        "    pred_class = most_common['most_common']\n",
        "\n",
        "  ## otherwise, class is based on majority class\n",
        "  else:\n",
        "    most_common = {'most_common': counts.most_common(1)[0][0]}\n",
        "    pred_class = most_common['most_common']\n",
        "\n",
        "  final_preds_dict[event_id] = pred_class"
      ],
      "metadata": {
        "id": "txL04FkrFmcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## take a peak at results\n",
        "Counter(final_preds_dict.values())"
      ],
      "metadata": {
        "id": "ReoLGkbKFoLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds_df = pd.DataFrame.from_dict(final_preds_dict.items())\n",
        "final_preds_df.columns=['event_id', 'pred_class']\n",
        "label_mapping = dict({0:'bear', 1: 'blank', 2: 'cottontail_snowshoehare', 3:'coyote', 4:'deer', 5:'elk', 6:'foxgray_foxred', 7:'opossum', 8:'raccoon', 9:'turkey', 10:'wolf'})\n",
        "final_preds_df['class_name'] = final_preds_df['pred_class'].map(label_mapping)"
      ],
      "metadata": {
        "id": "3hUW482_FsCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## get test labels\n",
        "test_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits4_1/yolo_splits4.1/test/test_labels.csv')\n",
        "test_data = test_data[test_data.CLASS_SPECIES_RESTATED != \"other\"]"
      ],
      "metadata": {
        "id": "turqkYweFvhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.merge(test_data, final_preds_df, how=\"inner\", left_on=['TRIGGER_ID'], right_on=['event_id'])\n",
        "test_actuals = comparison_df['CLASS_SPECIES_RESTATED'].values\n",
        "test_preds = comparison_df['class_name'].values"
      ],
      "metadata": {
        "id": "8D6DLCJ3Fy_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "class_names = ['bear', 'blank', 'cottontail_snowshoehare', 'coyote', 'deer', 'elk', 'foxgray_foxred', 'opossum', 'raccoon', 'turkey', 'wolf']\n",
        "confusion_matrix(test_actuals, test_preds, labels=class_names)"
      ],
      "metadata": {
        "id": "8C723r6FF1oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_actuals, test_preds, digits = 4))"
      ],
      "metadata": {
        "id": "hOcmB0JLF4Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = class_names\n",
        "columns = class_names\n",
        "\n",
        "cm = confusion_matrix(test_actuals, test_preds)\n",
        "cm_df = pd.DataFrame(cm, columns, index)\n",
        "plt.figure(figsize = (10,6))\n",
        "ax = sns.heatmap(cm_df, annot = True, fmt='d', cmap = \"Blues\")\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "#ax.get_ylim()\n",
        "ax.set_ylim(11, 0)"
      ],
      "metadata": {
        "id": "73ZPhVVLF7jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Event Level Top-K Predictions"
      ],
      "metadata": {
        "id": "qUYPEl1DF8Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model_results = pd.read_json('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/JSON_outputs/phase2_efficientnetb5_456_25epochs_yolo_splits4-1_test_classifications_basePlusblanks.json')\n",
        "df = model_results['phase2_classification_results'].apply(pd.Series)\n",
        "\n",
        "def extract_event_id(x):\n",
        "  if 'jpg' in x:\n",
        "    file = x.split('.jpg')[0]\n",
        "    event = file[:-1]\n",
        "    return event\n",
        "  else:\n",
        "    file = x.split('.jpeg')[0]\n",
        "    file = file.split('_')[0]\n",
        "    return file\n",
        "   \n",
        "df['event_id'] = df.apply(lambda x: extract_event_id(x.id), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2s6s8NsvF96Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "\n",
        "preds_dict = {}\n",
        "for index, row in df.iterrows():\n",
        "  event_id = str(row['event_id'])\n",
        "  conf_dict = row['conf_dict']\n",
        "  \n",
        "  result_dict = {\n",
        "        \"conf_dict\": conf_dict\n",
        "    }\n",
        "  \n",
        "  if event_id in preds_dict:\n",
        "    preds_dict[event_id].append(result_dict)\n",
        "  else:\n",
        "    preds_dict[event_id] = [result_dict]\n",
        "\n",
        "consol_dict = {}\n",
        "for item, list_dict in preds_dict.items():\n",
        "  itr = 0\n",
        "  length = len(list_dict)\n",
        "  event_id = item\n",
        "  while itr < length:\n",
        "    for k,v in list_dict[itr].items():\n",
        "      #print(k, v)\n",
        "      if event_id in consol_dict:\n",
        "        consol_dict[event_id].append(v)\n",
        "      else:\n",
        "        consol_dict[event_id] = [v]\n",
        "      #consol_dict.setdefault(k, []).append(v)\n",
        "      itr +=1\n",
        "\n",
        "consol_dict\n",
        "\n",
        "outer_dict = {}\n",
        "for key, value in consol_dict.items():\n",
        "  intermed_dict = {}\n",
        "  for sub_dict in value:\n",
        "    for k,v in sub_dict.items():\n",
        "      if k in intermed_dict:\n",
        "        intermed_dict[k].append(v[0])\n",
        "      else:\n",
        "        intermed_dict[k] = [v[0]]\n",
        "      outer_dict[key] = intermed_dict\n",
        "\n",
        "### get top 5 for each event\n",
        "final_top5_event_dict = {}\n",
        "for key, value in outer_dict.items():\n",
        "  top_ind = sorted(value, key=value.get, reverse=True)[:k] ### <--- top3 or top5\n",
        "  conf_scores = {}\n",
        "  for i in top_ind:\n",
        "    conf_scores[i] = max(value[i])\n",
        "  \n",
        "  final_top5_event_dict[key] = conf_scores\n",
        "\n",
        "final_top5_event_dict"
      ],
      "metadata": {
        "id": "VAw_wI7HGEHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top5_preds_df = pd.DataFrame.from_dict(final_top5_event_dict.items())\n",
        "top5_preds_df.columns=['event_id', 'pred_class']\n",
        "label_mapping = dict({0:'bear', 1: 'blank', 2: 'cottontail_snowshoehare', 3:'coyote', 4:'deer', 5:'elk', 6:'foxgray_foxred', 7:'opossum', 8:'raccoon', 9:'turkey', 10:'wolf'})\n",
        "\n",
        "def map_function(x):\n",
        "  output_dict = {}\n",
        "  for key, value in x.items():\n",
        "    animal_name = label_mapping[int(key)]\n",
        "    output_dict[animal_name] = value\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "top5_preds_df['mapped_preds'] = top5_preds_df['pred_class'].apply(lambda x: map_function(x))"
      ],
      "metadata": {
        "id": "XsP62geWGJcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits4_1/yolo_splits4.1/test/test_labels.csv')\n",
        "test_data = test_data[test_data.CLASS_SPECIES_RESTATED != \"other\"]"
      ],
      "metadata": {
        "id": "lqvOEf_TGMnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "get top1 predictions in case top5 is wrong (serve as wrong prediction in array)\n",
        "final_preds_dict is taken from the previous subsection for classification report at the top1 event level\n",
        "\"\"\"\n",
        "\n",
        "top1_preds_df = pd.DataFrame.from_dict(final_preds_dict.items())\n",
        "top1_preds_df.columns=['event_id', 'pred_class']\n",
        "label_mapping = dict({0:'bear', 1: 'blank', 2: 'cottontail_snowshoehare', 3:'coyote', 4:'deer', 5:'elk', 6:'foxgray_foxred', 7:'opossum', 8:'raccoon', 9:'turkey', 10:'wolf'})\n",
        "top1_preds_df['class_name'] = top1_preds_df['pred_class'].map(label_mapping)\n",
        "top1_preds_df.head()"
      ],
      "metadata": {
        "id": "GsVxZveYGPZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.merge(test_data, top1_preds_df, how=\"right\", left_on=['TRIGGER_ID'], right_on=['event_id'])\n",
        "comparison_df = pd.merge(comparison_df, top5_preds_df, how=\"right\", left_on=['TRIGGER_ID'], right_on=['event_id'] )\n",
        "comparison_df = comparison_df.drop(['event_id_x', 'event_id_y'], axis=1)\n",
        "comparison_df = comparison_df.rename(columns={\"pred_class_x\": \"top1_pred_class\", \"class_name\": \"top1_pred_class_name\", \"pred_class_y\": \"top5_preds\"})"
      ],
      "metadata": {
        "id": "rE-MErVXGR8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_species_present(x,y):\n",
        "  if x in y:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def confirm_top5_species(x, y, z):\n",
        "  if x == 1:\n",
        "    ## return top5 pred, which is the true label\n",
        "    return y\n",
        "  else:\n",
        "    ## return top1 pred (probably incorrect pred)\n",
        "    return z\n",
        "\n",
        "comparison_df['top5_present'] = comparison_df.apply(lambda x: check_species_present(x.CLASS_SPECIES_RESTATED, x.mapped_preds), axis=1)\n",
        "comparison_df['top5_species_pred'] = comparison_df.apply(lambda x: confirm_top5_species(x.top5_present, x.CLASS_SPECIES_RESTATED, x.top1_pred_class_name), axis=1)"
      ],
      "metadata": {
        "id": "E1zuw3TUGTwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_actuals = comparison_df['CLASS_SPECIES_RESTATED'].values\n",
        "test_preds = comparison_df['top5_species_pred'].values"
      ],
      "metadata": {
        "id": "s7-jayBIGYXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(test_actuals, test_preds, labels=class_names)"
      ],
      "metadata": {
        "id": "boRAFhCaGZWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_actuals, test_preds, digits = 4))"
      ],
      "metadata": {
        "id": "YnaW8WFpGafa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "index = class_names\n",
        "columns = class_names\n",
        "\n",
        "cm = confusion_matrix(test_actuals, test_preds)\n",
        "cm_df = pd.DataFrame(cm, columns, index)\n",
        "plt.figure(figsize = (10,6))\n",
        "ax = sns.heatmap(cm_df, annot = True, fmt='d', cmap = \"Blues\")\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "#ax.get_ylim()\n",
        "ax.set_ylim(11, 0)"
      ],
      "metadata": {
        "id": "hUvJSnaNGbcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature Scaling\n",
        "soften the confidence scores that are being output from the softmax layer"
      ],
      "metadata": {
        "id": "_-9spt52Gj5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gpleiss temp scaling program\n",
        "https://github.com/gpleiss/temperature_scaling"
      ],
      "metadata": {
        "id": "QkhPPYr5G6Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class ModelWithTemperature(nn.Module):\n",
        "    \"\"\"\n",
        "    A thin decorator, which wraps a model with temperature scaling\n",
        "    model (nn.Module):\n",
        "        A classification neural network\n",
        "        NB: Output of the neural network should be the classification logits,\n",
        "            NOT the softmax (or log softmax)!\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        super(ModelWithTemperature, self).__init__()\n",
        "        self.model = model\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, input):\n",
        "        logits = self.model(input)\n",
        "        return self.temperature_scale(logits)\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        \"\"\"\n",
        "        Perform temperature scaling on logits\n",
        "        \"\"\"\n",
        "        # Expand temperature to match the size of logits\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature\n",
        "\n",
        "    # This function probably should live outside of this class, but whatever\n",
        "    def set_temperature(self, valid_loader):\n",
        "        \"\"\"\n",
        "        Tune the tempearature of the model (using the validation set).\n",
        "        We're going to set it to optimize NLL.\n",
        "        valid_loader (DataLoader): validation set loader\n",
        "        \"\"\"\n",
        "        self.cuda()\n",
        "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
        "        ece_criterion = _ECELoss().cuda()\n",
        "\n",
        "        # First: collect all the logits and labels for the validation set\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "        with torch.no_grad():\n",
        "            for input, label in valid_loader:\n",
        "                input = input.cuda()\n",
        "                logits = self.model(input)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(label)\n",
        "            logits = torch.cat(logits_list).cuda()\n",
        "            labels = torch.cat(labels_list).cuda()\n",
        "\n",
        "        # Calculate NLL and ECE before temperature scaling\n",
        "        before_temperature_nll = nll_criterion(logits, labels).item()\n",
        "        before_temperature_ece = ece_criterion(logits, labels).item()\n",
        "        print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
        "\n",
        "        # Next: optimize the temperature w.r.t. NLL\n",
        "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
        "\n",
        "        def eval():\n",
        "            optimizer.zero_grad()\n",
        "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optimizer.step(eval)\n",
        "\n",
        "        # Calculate NLL and ECE after temperature scaling\n",
        "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
        "        print('Optimal temperature: %.3f' % self.temperature.item())\n",
        "        print('After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece))\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "class _ECELoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Calculates the Expected Calibration Error of a model.\n",
        "    (This isn't necessary for temperature scaling, just a cool metric).\n",
        "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
        "    This divides the confidence outputs into equally-sized interval bins.\n",
        "    In each bin, we compute the confidence gap:\n",
        "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
        "    We then return a weighted average of the gaps, based on the number\n",
        "    of samples in each bin\n",
        "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
        "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
        "    2015.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_bins=15):\n",
        "        \"\"\"\n",
        "        n_bins (int): number of confidence interval bins\n",
        "        \"\"\"\n",
        "        super(_ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "\n",
        "        ece = torch.zeros(1, device=logits.device)\n",
        "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "            # Calculated |confidence - accuracy| in each bin\n",
        "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "            prop_in_bin = in_bin.float().mean()\n",
        "            if prop_in_bin.item() > 0:\n",
        "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "        return ece"
      ],
      "metadata": {
        "id": "ESbcWcV6G5iq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint = torch.load(Path('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_model_runs/efficientnetb5_25epochs_finetuned_model_yolosplits4_456_BasePlusBlank.pt'))\n",
        "model_name = 'efficientnetb5'\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False) #change True/False\n",
        "model_ft.load_state_dict(checkpoint)\n",
        "\n",
        "val_loader = dataloaders_dict['val']\n",
        "test_loader = dataloaders_dict['test']\n",
        "\n",
        "scaled_model = ModelWithTemperature(model_ft)\n",
        "scaled_model.set_temperature(val_loader)\n",
        "\n",
        "## result: optimal temperature = 1.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsS7n4dEG5yo",
        "outputId": "18460737-1ef3-4980-c37f-6c5a65622089"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before temperature - NLL: 0.617, ECE: 0.018\n",
            "Optimal temperature: 1.286\n",
            "After temperature - NLL: 0.626, ECE: 0.049\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelWithTemperature(\n",
              "  (model): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (7): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (10): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (13): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (14): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (16): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (17): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (18): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (19): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (20): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (21): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (22): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (23): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (24): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (25): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (26): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (27): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (28): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (29): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (30): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (31): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (32): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (33): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (34): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (35): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (36): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (37): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (38): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.4, inplace=False)\n",
              "    (_fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      (1): Linear(in_features=512, out_features=11, bias=True)\n",
              "    )\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Before/After of Temp Scaling"
      ],
      "metadata": {
        "id": "MUzuw0RsKbfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint = torch.load(Path('/content/gdrive/My Drive/Colab Notebooks/w210_capstone/yolo_splits_torch_model_runs/efficientnetb5_25epochs_finetuned_model_yolosplits4_456_BasePlusBlank.pt'))\n",
        "model_name = 'efficientnetb5'\n",
        "net, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False) #change True/False\n",
        "net.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diYG18myGlPX",
        "outputId": "2dea7ff4-9277-4fc8-dc1c-9321b9885ac7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################### Testing ######################\n",
        "test_set = image_datasets['test']\n",
        "test_loader = dataloaders_dict['test']\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Use kwags for calibration method specific parameters\n",
        "def test(calibration_method=None, **kwargs):\n",
        "  preds = []\n",
        "  labels_oneh = []\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in tqdm(test_loader):\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          net.to(device)\n",
        "          pred = net(images)\n",
        "          \n",
        "          if calibration_method:\n",
        "            pred = calibration_method(pred, kwargs)\n",
        "\n",
        "          # Get softmax values for net input and resulting class predictions\n",
        "          sm = nn.Softmax(dim=1)\n",
        "          pred = sm(pred)\n",
        "\n",
        "          _, predicted_cl = torch.max(pred.data, 1)\n",
        "          pred = pred.cpu().detach().numpy()\n",
        "\n",
        "          # Convert labels to one hot encoding\n",
        "          label_oneh = torch.nn.functional.one_hot(labels, num_classes=num_classes)\n",
        "          label_oneh = label_oneh.cpu().detach().numpy()\n",
        "\n",
        "          preds.extend(pred)\n",
        "          labels_oneh.extend(label_oneh)\n",
        "\n",
        "          # Count correctly classified samples for accuracy\n",
        "          correct += sum(predicted_cl == labels).item()\n",
        "\n",
        "  preds = np.array(preds).flatten()\n",
        "  labels_oneh = np.array(labels_oneh).flatten()\n",
        "\n",
        "  correct_perc = correct / len(test_set)\n",
        "  print('Accuracy of the network on test images: %d %%' % (100 * correct_perc))\n",
        "  print(correct_perc)\n",
        "  \n",
        "  return preds, labels_oneh\n",
        "\n",
        "preds, labels_oneh = test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9f60b15dd3a542daa59c9dc4b28924e4",
            "ae65eb3493d1412cb0464eeca483ffd7",
            "45442bdb62e54dcca878d62004f1c89c",
            "d2c3660f135642ceba59f7e942922029",
            "349714b81d50464992aee74f35739ff6",
            "dadb7bc4196844fcb6203b5a8d0dbbc7",
            "bfb22df5a1ce4607bca49a77f45599e9",
            "a3b16398ecc2404088bc375da892a0fd",
            "a9840b13e46c447ba8fcf290cded8de1",
            "76877b954e9b4eeab32822242c2c13b9",
            "4034a6b18f0e423cb0ea385cf3460f82"
          ]
        },
        "id": "VWyXC7woGsSd",
        "outputId": "a120d8d7-8baa-4e5d-d8d0-b28cc62b8332"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f60b15dd3a542daa59c9dc4b28924e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on test images: 70 %\n",
            "0.7005235602094241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calibrated_test(calibration_method=None, **kwargs):\n",
        "  preds = []\n",
        "  labels_oneh = []\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in tqdm(test_loader):\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          net.to(device)\n",
        "          pred = net(images)\n",
        "\n",
        "          temperature = 1.29\n",
        "          pred = torch.div(pred, temperature)\n",
        "          \n",
        "          if calibration_method:\n",
        "            pred = calibration_method(pred, kwargs)\n",
        "\n",
        "          # Get softmax values for net input and resulting class predictions\n",
        "          sm = nn.Softmax(dim=1)\n",
        "          pred = sm(pred)\n",
        "\n",
        "          _, predicted_cl = torch.max(pred.data, 1)\n",
        "          pred = pred.cpu().detach().numpy()\n",
        "\n",
        "          # Convert labels to one hot encoding\n",
        "          label_oneh = torch.nn.functional.one_hot(labels, num_classes=num_classes)\n",
        "          label_oneh = label_oneh.cpu().detach().numpy()\n",
        "\n",
        "          preds.extend(pred)\n",
        "          labels_oneh.extend(label_oneh)\n",
        "\n",
        "          # Count correctly classified samples for accuracy\n",
        "          correct += sum(predicted_cl == labels).item()\n",
        "\n",
        "  preds = np.array(preds).flatten()\n",
        "  labels_oneh = np.array(labels_oneh).flatten()\n",
        "\n",
        "  correct_perc = correct / len(test_set)\n",
        "  print('Accuracy of the network on test images: %d %%' % (100 * correct_perc))\n",
        "  print(correct_perc)\n",
        "  \n",
        "  return preds, labels_oneh\n",
        "\n",
        "calibrated_preds, labels_oneh = calibrated_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "7d4b52a68a244dbdbf2527577aff8be1",
            "9654c0080b0d463388e693e23c350ea8",
            "5c79a54bcfda48aa9fbafa38054c777d",
            "858ec94e9a03450bb52fcc1bd4618ea2",
            "cdde1720c5ec44a3868ae40d853acb9b",
            "1a1d59d2682645e4a646a2a6ede7fb89",
            "2eb86d3a5fb24be5b12bbe498dcd65f1",
            "ee8fdf5f32e54c29a801523fa20b25bf",
            "6be3292115e54434851e04aa520e22c9",
            "e5560dbae5f44fad814c9e7d36d1fc3d",
            "46c9b60bac88480083ca0bd664d5f91e"
          ]
        },
        "id": "kBWiibWGGtzv",
        "outputId": "6f851578-dda2-4115-c4d2-8d3d948465f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4b52a68a244dbdbf2527577aff8be1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/597 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on test images: 70 %\n",
            "0.7005235602094241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bins(preds):\n",
        "  # Assign each prediction to a bin\n",
        "  num_bins = 10\n",
        "  bins = np.linspace(0.1, 1, num_bins)\n",
        "  binned = np.digitize(preds, bins)\n",
        "\n",
        "  # Save the accuracy, confidence and size of each bin\n",
        "  bin_accs = np.zeros(num_bins)\n",
        "  bin_confs = np.zeros(num_bins)\n",
        "  bin_sizes = np.zeros(num_bins)\n",
        "\n",
        "  for bin in range(num_bins):\n",
        "    bin_sizes[bin] = len(preds[binned == bin])\n",
        "    if bin_sizes[bin] > 0:\n",
        "      bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
        "      bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
        "\n",
        "  return bins, binned, bin_accs, bin_confs, bin_sizes\n",
        "\n",
        "def get_metrics(preds):\n",
        "  ECE = 0\n",
        "  MCE = 0\n",
        "  bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds)\n",
        "\n",
        "  for i in range(len(bins)):\n",
        "    abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
        "    ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
        "    MCE = max(MCE, abs_conf_dif)\n",
        "\n",
        "  return ECE, MCE"
      ],
      "metadata": {
        "id": "XCG_398jGvIr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reliability Diagrams"
      ],
      "metadata": {
        "id": "C_i-quAuGxU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "def draw_reliability_graph(preds):\n",
        "  ECE, MCE = get_metrics(preds)\n",
        "  bins, _, bin_accs, _, _ = calc_bins(preds)\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  ax = fig.gca()\n",
        "\n",
        "  # x/y limits\n",
        "  ax.set_xlim(0, 1.05)\n",
        "  ax.set_ylim(0, 1)\n",
        "\n",
        "  # x/y labels\n",
        "  plt.xlabel('Confidence')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # Create grid\n",
        "  ax.set_axisbelow(True) \n",
        "  ax.grid(color='gray', linestyle='dashed')\n",
        "\n",
        "  # Error bars\n",
        "  plt.bar(bins, bins,  width=0.1, alpha=0.3, edgecolor='black', color='r', hatch='\\\\')\n",
        "\n",
        "  # Draw bars and identity line\n",
        "  plt.bar(bins, bin_accs, width=0.1, alpha=1, edgecolor='black', color='b')\n",
        "  plt.plot([0,1],[0,1], '--', color='gray', linewidth=2)\n",
        "\n",
        "  # Equally spaced axes\n",
        "  plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "  # ECE and MCE legend\n",
        "  ECE_patch = mpatches.Patch(color='green', label='ECE = {:.2f}%'.format(ECE*100))\n",
        "  MCE_patch = mpatches.Patch(color='red', label='MCE = {:.2f}%'.format(MCE*100))\n",
        "  plt.legend(handles=[ECE_patch, MCE_patch])\n",
        "\n",
        "  #plt.show()\n",
        "  \n",
        "  plt.savefig('calibrated_network.png', bbox_inches='tight')\n",
        "\n",
        "\n",
        "### pre-calibration\n",
        "draw_reliability_graph(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "E8grRIh0GxCu",
        "outputId": "9823b73f-b43d-4166-fea3-794fc9b940b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## temperature = 1.29\n",
        "## post-calibration on validation\n",
        "draw_reliability_graph(calibrated_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "coLBCYmdGzxS",
        "outputId": "8ef7c99d-ed1b-4eee-b755-625d3b9599d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}